{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4380d1b4",
   "metadata": {},
   "source": [
    "# üé® Stable Diffusion Backend Server for Frontend\n",
    "### Google Colab + Cloudflared Tunnel\n",
    "**Use with**: Your HTML/JS/CSS Frontend (Github Pages, Local, etc.)\n",
    "\n",
    "This notebook provides a complete API backend for text-to-image, image-to-image, and inpainting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564a053",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e63d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision diffusers transformers accelerate safetensors flask flask-cors pyngrok pillow numpy xformers\n",
    "print('‚úÖ Dependencies installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0bb086",
   "metadata": {},
   "source": [
    "## Step 2: Install Cloudflared for HTTPS Tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcd35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install cloudflared\n",
    "!wget -q https://github.com/cloudflare/wrangler/releases/download/wrangler-3.0.1/cloudflared-linux-amd64.deb -O /tmp/cloudflared.deb\n",
    "!dpkg -i /tmp/cloudflared.deb > /dev/null 2>&1\n",
    "print('‚úÖ Cloudflared installed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d2755",
   "metadata": {},
   "source": [
    "## Step 3: Load Stable Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88315ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import threading\n",
    "import os\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'üñ•Ô∏è Using device: {device}')\n",
    "\n",
    "# Model ID (can be changed)\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "print(f'üì¶ Loading model: {MODEL_ID}...')\n",
    "\n",
    "# Load pipelines\n",
    "try:\n",
    "    print('Loading txt2img pipeline...')\n",
    "    pipe_txt2img = StableDiffusionPipeline.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        safety_checker=None\n",
    "    ).to(device)\n",
    "    pipe_txt2img.enable_xformers_memory_efficient_attention()\n",
    "    print('‚úÖ txt2img loaded')\n",
    "    \n",
    "    print('Loading img2img pipeline...')\n",
    "    pipe_img2img = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        safety_checker=None\n",
    "    ).to(device)\n",
    "    pipe_img2img.enable_xformers_memory_efficient_attention()\n",
    "    print('‚úÖ img2img loaded')\n",
    "    \n",
    "    print('Loading inpaint pipeline...')\n",
    "    pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "        safety_checker=None\n",
    "    ).to(device)\n",
    "    pipe_inpaint.enable_xformers_memory_efficient_attention()\n",
    "    print('‚úÖ inpaint loaded')\n",
    "    \n",
    "    print('\\n‚úÖ All pipelines ready!')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Error loading models: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c2d4c",
   "metadata": {},
   "source": [
    "## Step 4: Create Flask API Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Global variables for progress tracking\n",
    "generation_progress = {\"current\": 0, \"total\": 0}\n",
    "is_generating = False\n",
    "\n",
    "def image_to_base64(image):\n",
    "    \"\"\"Convert PIL Image to base64 string\"\"\"\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"PNG\")\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "    return f\"data:image/png;base64,{img_str}\"\n",
    "\n",
    "def base64_to_image(base64_str):\n",
    "    \"\"\"Convert base64 string to PIL Image\"\"\"\n",
    "    # Remove data URI prefix if present\n",
    "    if ',' in base64_str:\n",
    "        base64_str = base64_str.split(',')[1]\n",
    "    \n",
    "    image_data = base64.b64decode(base64_str)\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    return image.convert('RGB')\n",
    "\n",
    "# API Endpoints\n",
    "\n",
    "@app.route('/api/health', methods=['GET'])\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\"status\": \"healthy\", \"message\": \"Server is running\"}), 200\n",
    "\n",
    "@app.route('/api/txt2img', methods=['POST'])\n",
    "def txt2img():\n",
    "    \"\"\"Text to image generation\"\"\"\n",
    "    global is_generating\n",
    "    \n",
    "    try:\n",
    "        if is_generating:\n",
    "            return jsonify({\"error\": \"Generation already in progress\"}), 429\n",
    "        \n",
    "        is_generating = True\n",
    "        data = request.json\n",
    "        \n",
    "        # Get parameters\n",
    "        prompt = data.get('prompt', '')\n",
    "        negative_prompt = data.get('negative_prompt', '')\n",
    "        steps = int(data.get('steps', 20))\n",
    "        cfg_scale = float(data.get('cfg_scale', 7.5))\n",
    "        width = int(data.get('width', 512))\n",
    "        height = int(data.get('height', 512))\n",
    "        seed = int(data.get('seed', -1))\n",
    "        batch_size = int(data.get('batch_size', 1))\n",
    "        \n",
    "        # Set seed if provided\n",
    "        if seed >= 0:\n",
    "            generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        else:\n",
    "            generator = None\n",
    "        \n",
    "        print(f'üé® Generating txt2img: \"{prompt}\"')\n",
    "        \n",
    "        # Generate images\n",
    "        result = pipe_txt2img(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=cfg_scale,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            num_images_per_prompt=batch_size,\n",
    "            generator=generator\n",
    "        )\n",
    "        \n",
    "        # Convert images to base64\n",
    "        images = [image_to_base64(img) for img in result.images]\n",
    "        \n",
    "        is_generating = False\n",
    "        return jsonify({\"success\": True, \"images\": images}), 200\n",
    "    \n",
    "    except Exception as e:\n",
    "        is_generating = False\n",
    "        print(f'‚ùå Error in txt2img: {e}')\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/api/img2img', methods=['POST'])\n",
    "def img2img():\n",
    "    \"\"\"Image to image generation\"\"\"\n",
    "    global is_generating\n",
    "    \n",
    "    try:\n",
    "        if is_generating:\n",
    "            return jsonify({\"error\": \"Generation already in progress\"}), 429\n",
    "        \n",
    "        is_generating = True\n",
    "        data = request.json\n",
    "        \n",
    "        # Get parameters\n",
    "        prompt = data.get('prompt', '')\n",
    "        negative_prompt = data.get('negative_prompt', '')\n",
    "        image_base64 = data.get('image', '')\n",
    "        steps = int(data.get('steps', 20))\n",
    "        cfg_scale = float(data.get('cfg_scale', 7.5))\n",
    "        strength = float(data.get('strength', 0.8))\n",
    "        seed = int(data.get('seed', -1))\n",
    "        batch_size = int(data.get('batch_size', 1))\n",
    "        \n",
    "        # Convert base64 to image\n",
    "        image = base64_to_image(image_base64)\n",
    "        \n",
    "        # Set seed if provided\n",
    "        if seed >= 0:\n",
    "            generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        else:\n",
    "            generator = None\n",
    "        \n",
    "        print(f'üé® Generating img2img: \"{prompt}\" (strength: {strength})')\n",
    "        \n",
    "        # Generate images\n",
    "        result = pipe_img2img(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=image,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=cfg_scale,\n",
    "            strength=strength,\n",
    "            num_images_per_prompt=batch_size,\n",
    "            generator=generator\n",
    "        )\n",
    "        \n",
    "        # Convert images to base64\n",
    "        images = [image_to_base64(img) for img in result.images]\n",
    "        \n",
    "        is_generating = False\n",
    "        return jsonify({\"success\": True, \"images\": images}), 200\n",
    "    \n",
    "    except Exception as e:\n",
    "        is_generating = False\n",
    "        print(f'‚ùå Error in img2img: {e}')\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/api/inpaint', methods=['POST'])\n",
    "def inpaint():\n",
    "    \"\"\"Inpainting generation\"\"\"\n",
    "    global is_generating\n",
    "    \n",
    "    try:\n",
    "        if is_generating:\n",
    "            return jsonify({\"error\": \"Generation already in progress\"}), 429\n",
    "        \n",
    "        is_generating = True\n",
    "        data = request.json\n",
    "        \n",
    "        # Get parameters\n",
    "        prompt = data.get('prompt', '')\n",
    "        negative_prompt = data.get('negative_prompt', '')\n",
    "        image_base64 = data.get('image', '')\n",
    "        mask_base64 = data.get('mask', '')\n",
    "        steps = int(data.get('steps', 20))\n",
    "        cfg_scale = float(data.get('cfg_scale', 7.5))\n",
    "        strength = float(data.get('strength', 0.8))\n",
    "        seed = int(data.get('seed', -1))\n",
    "        batch_size = int(data.get('batch_size', 1))\n",
    "        \n",
    "        # Convert base64 to images\n",
    "        image = base64_to_image(image_base64)\n",
    "        mask = base64_to_image(mask_base64).convert('L')\n",
    "        \n",
    "        # Set seed if provided\n",
    "        if seed >= 0:\n",
    "            generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        else:\n",
    "            generator = None\n",
    "        \n",
    "        print(f'üé® Generating inpaint: \"{prompt}\"')\n",
    "        \n",
    "        # Generate images\n",
    "        result = pipe_inpaint(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image=image,\n",
    "            mask_image=mask,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=cfg_scale,\n",
    "            strength=strength,\n",
    "            num_images_per_prompt=batch_size,\n",
    "            generator=generator\n",
    "        )\n",
    "        \n",
    "        # Convert images to base64\n",
    "        images = [image_to_base64(img) for img in result.images]\n",
    "        \n",
    "        is_generating = False\n",
    "        return jsonify({\"success\": True, \"images\": images}), 200\n",
    "    \n",
    "    except Exception as e:\n",
    "        is_generating = False\n",
    "        print(f'‚ùå Error in inpaint: {e}')\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/api/progress', methods=['GET'])\n",
    "def progress():\n",
    "    \"\"\"Get generation progress\"\"\"\n",
    "    return jsonify({\"is_generating\": is_generating}), 200\n",
    "\n",
    "@app.route('/api/interrupt', methods=['POST'])\n",
    "def interrupt():\n",
    "    \"\"\"Interrupt generation\"\"\"\n",
    "    global is_generating\n",
    "    is_generating = False\n",
    "    return jsonify({\"success\": True}), 200\n",
    "\n",
    "print('\\n‚úÖ Flask app configured with endpoints:')\n",
    "print('  ‚Ä¢ GET  /api/health')\n",
    "print('  ‚Ä¢ POST /api/txt2img')\n",
    "print('  ‚Ä¢ POST /api/img2img')\n",
    "print('  ‚Ä¢ POST /api/inpaint')\n",
    "print('  ‚Ä¢ GET  /api/progress')\n",
    "print('  ‚Ä¢ POST /api/interrupt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b4512",
   "metadata": {},
   "source": [
    "## Step 5: Start Cloudflared Tunnel (HTTPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e277c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "\n",
    "# Start cloudflared in background\n",
    "cloudflared_process = None\n",
    "\n",
    "def start_cloudflared():\n",
    "    \"\"\"Start cloudflared tunnel\"\"\"\n",
    "    global cloudflared_process\n",
    "    try:\n",
    "        cloudflared_process = subprocess.Popen(\n",
    "            ['cloudflared', 'tunnel', '--url', 'http://localhost:5000'],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        # Read output to get tunnel URL\n",
    "        for line in cloudflared_process.stdout:\n",
    "            if 'https://' in line:\n",
    "                tunnel_url = line.split('https://')[1].split()[0]\n",
    "                print(f'\\nüåê Cloudflared tunnel URL: https://{tunnel_url}')\n",
    "                print('\\nüìã Use this URL in your frontend!')\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error starting cloudflared: {e}')\n",
    "\n",
    "print('Starting cloudflared tunnel...')\n",
    "cloudflared_thread = threading.Thread(target=start_cloudflared, daemon=True)\n",
    "cloudflared_thread.start()\n",
    "time.sleep(2)\n",
    "print('‚úÖ Cloudflared starting...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c40086",
   "metadata": {},
   "source": [
    "## Step 6: Start Flask Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d0188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Flask server\n",
    "def run_flask():\n",
    "    app.run(host='127.0.0.1', port=5000, debug=False, use_reloader=False)\n",
    "\n",
    "flask_thread = threading.Thread(target=run_flask, daemon=True)\n",
    "flask_thread.start()\n",
    "\n",
    "print('\\nüöÄ Flask server started on http://localhost:5000')\n",
    "print('\\n‚úÖ Backend is ready!')\n",
    "print('\\nNext steps:')\n",
    "print('1. Copy the cloudflared tunnel URL from above')\n",
    "print('2. Go to your frontend app')\n",
    "print('3. Paste the URL in #settings tab')\n",
    "print('4. Click \"Test Connection\"')\n",
    "print('5. Start generating images!')\n",
    "\n",
    "# Keep the notebook running\n",
    "import time\n",
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n\\n‚è∏Ô∏è  Server stopped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf2bba7",
   "metadata": {},
   "source": [
    "## Step 7: Test the API (Optional)\n",
    "Run this cell to test if the server is working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Test health endpoint\n",
    "try:\n",
    "    response = requests.get('http://localhost:5000/api/health', timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print('‚úÖ API is responding')\n",
    "        print(json.dumps(response.json(), indent=2))\n",
    "    else:\n",
    "        print('‚ùå API returned error:', response.status_code)\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Cannot connect to API: {e}')\n",
    "    print('Make sure Step 6 is running')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
